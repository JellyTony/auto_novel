server:
  http:
    addr: 0.0.0.0:8000
    timeout: 600s
  grpc:
    addr: 0.0.0.0:9000
    timeout: 600s
data:
  database:
    driver: mysql
    source: root:root@tcp(127.0.0.1:3306)/test?parseTime=True&loc=Local
  redis:
    addr: 127.0.0.1:6379
    read_timeout: 0.2s
    write_timeout: 0.2s
  vector:
    embedding:
      provider: "openai"  # openai, azure, local
      api_key: ""
      base_url: "https://api.openai.com/v1"
      model: "text-embedding-ada-002"
      timeout: 30
ai:
  models:
    # 默认模型配置
    default:
      provider: "deepseek"
      model_name: "deepseek-chat"
      api_key: "sk-037a79e3a5cd41b9ba49e92bd2a54e35"
      base_url: "https://api.deepseek.com/"
      temperature: 0.8
      max_tokens: 4096
      top_p: 1.0
      timeout: 600s
    # 可选的其他模型配置
    creative:
      provider: "deepseek"
      model_name: "deepseek-chat"
      api_key: "sk-037a79e3a5cd41b9ba49e92bd2a54e35"
      base_url: "https://api.deepseek.com/"
      temperature: 1.0
      max_tokens: 4096
      top_p: 0.9
      timeout: 600s
    # Qwen模型配置
    qwen:
      provider: "qwen"
      model_name: "qwen-turbo"
      api_key: ""  # 需要配置Qwen API Key
      base_url: "https://dashscope.aliyuncs.com/api/v1"
      temperature: 0.8
      max_tokens: 4096
      top_p: 1.0
      timeout: 300s
    # Ollama本地模型配置
    ollama:
      provider: "ollama"
      model_name: "llama2"  # 或其他本地模型名称
      api_key: ""  # Ollama不需要API Key
      base_url: "http://localhost:11434"
      temperature: 0.8
      max_tokens: 4096
      top_p: 1.0
      timeout: 300s
    reasoning:
      provider: "deepseek"
      model_name: "deepseek-reasoner"
      api_key: "sk-037a79e3a5cd41b9ba49e92bd2a54e35"
      base_url: "https://api.deepseek.com/"
      temperature: 0.3
      max_tokens: 8192
      top_p: 0.8
      timeout: 600s
